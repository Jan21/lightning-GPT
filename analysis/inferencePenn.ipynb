{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data has 612173 characters, 50000 unique.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "number of parameters: 6.60M\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath('.'))\n",
    "sys.path.insert(0, currentdir)\n",
    "\n",
    "from lightning_gpt import data, models\n",
    "from tokenizers import (\n",
    "    Tokenizer,\n",
    "    decoders\n",
    ")\n",
    "\n",
    "version = 8\n",
    "checkpoint_dir = f'{currentdir}/temp/checkpoints/version_{version}/'\n",
    "#load hparams.yaml\n",
    "import yaml\n",
    "with open(f'{checkpoint_dir}hparams.yaml') as file:\n",
    "    hparams = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "block_size = hparams['block_size']\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "model_type = hparams['model_type']\n",
    "n_layer = hparams['n_layer']\n",
    "n_head = hparams['n_head']\n",
    "n_embd = hparams['n_embd']\n",
    "learning_rate = hparams['learning_rate']\n",
    "\n",
    "tokenizer = Tokenizer.from_file(f\"{currentdir}/temp/tokenizerBPE.json\")\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "test_file = f'{currentdir}/temp/val.bin'\n",
    "test_dataset = data.cc_czech_Dataset(test_file, block_size,tokenizer)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "extra_kwargs = {}\n",
    "\n",
    "extra_kwargs[\"dropout\"] = 0.1\n",
    "\n",
    "model = models.NanoGPTExport(\n",
    "    vocab_size=test_dataset.vocab_size,\n",
    "    block_size=test_dataset.block_size,\n",
    "    model_type=model_type,\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    n_embd=n_embd,\n",
    "    weight_decay=0.1,\n",
    "    learning_rate=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    **extra_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\n",
      "number of parameters: 95.10M\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = f'{checkpoint_dir}checkpoints/epoch=99-step=368400.ckpt'\n",
    "model = model.load_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=NanoGPTExport\n",
       "  (nanogpt): RecursiveScriptModule(\n",
       "    original_name=GPTExport\n",
       "    (transformer): RecursiveScriptModule(\n",
       "      original_name=ModuleDict\n",
       "      (wte): RecursiveScriptModule(original_name=Embedding)\n",
       "      (wpe): RecursiveScriptModule(original_name=Embedding)\n",
       "      (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      (h): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (1): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (2): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (3): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (4): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (5): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (6): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (7): RecursiveScriptModule(\n",
       "          original_name=Block\n",
       "          (ln_1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (attn): RecursiveScriptModule(\n",
       "            original_name=CausalSelfAttention\n",
       "            (c_attn): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (attn_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "            (resid_dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "          (ln_2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (mlp): RecursiveScriptModule(\n",
       "            original_name=MLP\n",
       "            (c_fc): RecursiveScriptModule(original_name=Linear)\n",
       "            (c_proj): RecursiveScriptModule(original_name=Linear)\n",
       "            (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): RecursiveScriptModule(original_name=LayerNorm)\n",
       "    )\n",
       "    (lm_head): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export model to torchscript\n",
    "model = model.eval()\n",
    "model = model.cpu()\n",
    "model.to_torchscript(f'{checkpoint_dir}model.pt')\n",
    "\n",
    "#model.save(f'{checkpoint_dir}model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath('.'))\n",
    "sys.path.insert(0, currentdir)\n",
    "version = 8\n",
    "checkpoint_dir = f'{currentdir}/temp/checkpoints/version_{version}/'\n",
    "model = torch.jit.load(f\"{checkpoint_dir}model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m context \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPrezident české republiky bude\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Prime with something\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x \u001b[39m=\u001b[39m test_dataset\u001b[39m.\u001b[39mto_tokens(context,\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m y \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      4\u001b[0m \u001b[39m#print(test_dataset.from_tokens(y.tolist()[0]))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "context = \"Prezident české republiky bude\"  # Prime with something\n",
    "x = test_dataset.to_tokens(context,'cpu')\n",
    "y = model(x)\n",
    "#print(test_dataset.from_tokens(y.tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "def generate(model,idx, max_new_tokens, block_size=128, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits = model(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make gradio interface which takes in a string as an input and outputs a number\n",
    "import gradio as gr\n",
    "def inference(context):\n",
    "    x = test_dataset.to_tokens(context, 'cpu')\n",
    "    y = generate(model, x, max_new_tokens=100, block_size=128, temperature=1.0, top_k=10)\n",
    "    return test_dataset.from_tokens(y.tolist()[0])\n",
    "\n",
    "gr.Interface(inference, \"text\", \"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5]) torch.Size([1, 5, 50000])\n",
      "torch.Size([1, 4]) torch.Size([1, 4, 50000])\n",
      "torch.Size([1, 5]) torch.Size([1, 5, 50000])\n",
      "torch.Size([1, 5]) torch.Size([1, 5, 50000])\n",
      "torch.Size([1, 7]) torch.Size([1, 7, 50000])\n",
      "torch.Size([1, 6]) torch.Size([1, 6, 50000])\n",
      "torch.Size([1, 5]) torch.Size([1, 5, 50000])\n",
      "torch.Size([1, 7]) torch.Size([1, 7, 50000])\n",
      "torch.Size([1, 6]) torch.Size([1, 6, 50000])\n",
      "torch.Size([1, 4]) torch.Size([1, 4, 50000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gradio as gr\n",
    "def inferencePepr(context):\n",
    "    x = test_dataset.to_tokens(context, 'cpu')\n",
    "    logits = model(x)\n",
    "    print(x.shape,logits.shape)\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1))[:-1], x.view(-1)[1:], ignore_index=-1).exp()\n",
    "     #loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), x.view(-1), reduction='none').view(x.size(0), -1).sum(1).mean().exp()\n",
    "    return f\"Perplexity: {loss}\"\n",
    "gr.Interface(inferencePepr, \"text\", \"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "Perplexity: 93.15540943723737\n"
     ]
    }
   ],
   "source": [
    "from torch.functional import F\n",
    "perplexities = []\n",
    "model = model.eval()\n",
    "model = model.cpu()\n",
    "for i,data in enumerate(test_loader):\n",
    "    x,y = data\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), ignore_index=-1)\n",
    "    perplexities.append(loss.exp().item())\n",
    "    print(i)\n",
    "print(f\"Perplexity: {sum(perplexities)/len(perplexities)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[197,\n",
       "  2373,\n",
       "  33,\n",
       "  867,\n",
       "  2142,\n",
       "  429,\n",
       "  10867,\n",
       "  15484,\n",
       "  15484,\n",
       "  2127,\n",
       "  2127,\n",
       "  36785,\n",
       "  36785,\n",
       "  31076,\n",
       "  4672,\n",
       "  4672,\n",
       "  29868,\n",
       "  31540,\n",
       "  9601,\n",
       "  9601,\n",
       "  40550,\n",
       "  42754,\n",
       "  34371,\n",
       "  8463,\n",
       "  13303,\n",
       "  38525,\n",
       "  546,\n",
       "  25597,\n",
       "  25597,\n",
       "  39468,\n",
       "  16591,\n",
       "  33805,\n",
       "  14723,\n",
       "  24611,\n",
       "  2776,\n",
       "  31036,\n",
       "  28202,\n",
       "  23911,\n",
       "  23911,\n",
       "  11362,\n",
       "  7753,\n",
       "  44529,\n",
       "  42547,\n",
       "  12625,\n",
       "  2480,\n",
       "  25875,\n",
       "  11818,\n",
       "  4625,\n",
       "  12687,\n",
       "  38143,\n",
       "  842,\n",
       "  15371,\n",
       "  9968,\n",
       "  37434,\n",
       "  13323,\n",
       "  1678,\n",
       "  1678,\n",
       "  25954,\n",
       "  43125,\n",
       "  43125,\n",
       "  37160,\n",
       "  43747,\n",
       "  44920,\n",
       "  6550,\n",
       "  27462,\n",
       "  27462,\n",
       "  27462,\n",
       "  43567,\n",
       "  7794,\n",
       "  41934,\n",
       "  41934,\n",
       "  28222,\n",
       "  26177,\n",
       "  32461,\n",
       "  7374,\n",
       "  30186,\n",
       "  13317,\n",
       "  8981,\n",
       "  45675,\n",
       "  42610,\n",
       "  34041,\n",
       "  15749,\n",
       "  15404,\n",
       "  17192,\n",
       "  42049,\n",
       "  42049,\n",
       "  176,\n",
       "  42581,\n",
       "  43912,\n",
       "  28733,\n",
       "  39813,\n",
       "  45201,\n",
       "  28005,\n",
       "  47204,\n",
       "  15554,\n",
       "  29279,\n",
       "  37265,\n",
       "  37265,\n",
       "  37265,\n",
       "  39076,\n",
       "  6639,\n",
       "  4161,\n",
       "  6568,\n",
       "  6568,\n",
       "  31493,\n",
       "  16450,\n",
       "  14121,\n",
       "  32275,\n",
       "  47166,\n",
       "  4064,\n",
       "  3521,\n",
       "  15874,\n",
       "  46299,\n",
       "  12730,\n",
       "  40644,\n",
       "  6712,\n",
       "  14724,\n",
       "  42151,\n",
       "  40527,\n",
       "  26851,\n",
       "  33191,\n",
       "  13604,\n",
       "  45849,\n",
       "  5702,\n",
       "  47352,\n",
       "  31209,\n",
       "  18715,\n",
       "  4582,\n",
       "  15392,\n",
       "  2608,\n",
       "  2608,\n",
       "  32950,\n",
       "  6664,\n",
       "  41231,\n",
       "  17558,\n",
       "  30406,\n",
       "  3662,\n",
       "  7016,\n",
       "  5409,\n",
       "  28696,\n",
       "  4270,\n",
       "  43628,\n",
       "  25215,\n",
       "  22599,\n",
       "  22599,\n",
       "  10549,\n",
       "  47376,\n",
       "  9639,\n",
       "  30584,\n",
       "  25706,\n",
       "  4152,\n",
       "  15322,\n",
       "  15322,\n",
       "  4152,\n",
       "  4647,\n",
       "  30503,\n",
       "  5795,\n",
       "  20712,\n",
       "  20712,\n",
       "  19662,\n",
       "  36879,\n",
       "  43898,\n",
       "  51,\n",
       "  8140,\n",
       "  15969,\n",
       "  3183,\n",
       "  12038,\n",
       "  24665,\n",
       "  36440,\n",
       "  28317,\n",
       "  3662,\n",
       "  48844,\n",
       "  32467,\n",
       "  6466,\n",
       "  6466,\n",
       "  16609,\n",
       "  4005,\n",
       "  12480,\n",
       "  24164,\n",
       "  1406,\n",
       "  1406,\n",
       "  48246,\n",
       "  22878,\n",
       "  25706,\n",
       "  18748,\n",
       "  23709,\n",
       "  30158,\n",
       "  564,\n",
       "  9639,\n",
       "  9639,\n",
       "  601,\n",
       "  31497,\n",
       "  9193,\n",
       "  28227,\n",
       "  16994,\n",
       "  8725,\n",
       "  30225,\n",
       "  25706,\n",
       "  13732,\n",
       "  25706,\n",
       "  44223,\n",
       "  47914,\n",
       "  19662,\n",
       "  19449,\n",
       "  24332,\n",
       "  24332,\n",
       "  49738,\n",
       "  49738,\n",
       "  19662,\n",
       "  48884,\n",
       "  19662,\n",
       "  19662,\n",
       "  20787,\n",
       "  41707,\n",
       "  41707,\n",
       "  28295,\n",
       "  28295,\n",
       "  40099,\n",
       "  31209,\n",
       "  13666,\n",
       "  37119,\n",
       "  18748,\n",
       "  37813,\n",
       "  21949,\n",
       "  14286,\n",
       "  25706,\n",
       "  6777,\n",
       "  9494,\n",
       "  46335,\n",
       "  17796,\n",
       "  13489,\n",
       "  22238,\n",
       "  27481,\n",
       "  20524,\n",
       "  8725,\n",
       "  25706,\n",
       "  32291,\n",
       "  3005,\n",
       "  9245,\n",
       "  19277,\n",
       "  19277,\n",
       "  32209,\n",
       "  32209,\n",
       "  22864,\n",
       "  7287,\n",
       "  43849,\n",
       "  21866,\n",
       "  30225,\n",
       "  30225,\n",
       "  48528,\n",
       "  48528,\n",
       "  10891,\n",
       "  40372,\n",
       "  28744,\n",
       "  32771,\n",
       "  2694,\n",
       "  34927,\n",
       "  34927,\n",
       "  26055,\n",
       "  36854,\n",
       "  49738,\n",
       "  19662,\n",
       "  38376,\n",
       "  6771,\n",
       "  46858,\n",
       "  33635,\n",
       "  24908,\n",
       "  40161,\n",
       "  21919,\n",
       "  38540,\n",
       "  36906,\n",
       "  46634,\n",
       "  47068,\n",
       "  25706,\n",
       "  25706,\n",
       "  37312,\n",
       "  25706,\n",
       "  26069,\n",
       "  20743,\n",
       "  29252,\n",
       "  29252,\n",
       "  29252,\n",
       "  49738,\n",
       "  29252,\n",
       "  29252,\n",
       "  22405,\n",
       "  25185,\n",
       "  46893,\n",
       "  21066,\n",
       "  20524,\n",
       "  33903,\n",
       "  1093,\n",
       "  28317,\n",
       "  24639,\n",
       "  19205,\n",
       "  49404,\n",
       "  6756,\n",
       "  6756,\n",
       "  1977,\n",
       "  40584,\n",
       "  49738,\n",
       "  11385,\n",
       "  24999,\n",
       "  28317,\n",
       "  15930,\n",
       "  15930,\n",
       "  15930,\n",
       "  17558,\n",
       "  17558,\n",
       "  2608,\n",
       "  2608,\n",
       "  5409,\n",
       "  5409,\n",
       "  41670,\n",
       "  5409,\n",
       "  14646,\n",
       "  22499,\n",
       "  22499,\n",
       "  22499,\n",
       "  22289,\n",
       "  35556,\n",
       "  10190,\n",
       "  18853,\n",
       "  19348,\n",
       "  19348,\n",
       "  5281,\n",
       "  38976,\n",
       "  25583,\n",
       "  25583,\n",
       "  25583,\n",
       "  20524,\n",
       "  10416,\n",
       "  10416,\n",
       "  10416,\n",
       "  40940,\n",
       "  8262,\n",
       "  37646,\n",
       "  28089,\n",
       "  21889,\n",
       "  34070,\n",
       "  10812,\n",
       "  10812,\n",
       "  4005,\n",
       "  4005,\n",
       "  40372,\n",
       "  23582,\n",
       "  15667,\n",
       "  37631,\n",
       "  28993,\n",
       "  6086,\n",
       "  29674,\n",
       "  36705,\n",
       "  17558,\n",
       "  17558,\n",
       "  32617,\n",
       "  34957,\n",
       "  34070,\n",
       "  15038,\n",
       "  15038,\n",
       "  13942,\n",
       "  27184,\n",
       "  20549,\n",
       "  46046,\n",
       "  13880,\n",
       "  39983,\n",
       "  39983,\n",
       "  10416,\n",
       "  17174,\n",
       "  32291,\n",
       "  25706,\n",
       "  45833,\n",
       "  45833,\n",
       "  45833,\n",
       "  36110,\n",
       "  48327,\n",
       "  37322,\n",
       "  4005,\n",
       "  41670,\n",
       "  25952,\n",
       "  6396,\n",
       "  6396,\n",
       "  6396,\n",
       "  24908,\n",
       "  29012,\n",
       "  29012,\n",
       "  46614,\n",
       "  26289,\n",
       "  34329,\n",
       "  45296,\n",
       "  21866,\n",
       "  21866,\n",
       "  32528,\n",
       "  28696,\n",
       "  7268,\n",
       "  27723,\n",
       "  7268,\n",
       "  7268,\n",
       "  7178,\n",
       "  19662,\n",
       "  19662,\n",
       "  17275,\n",
       "  15363,\n",
       "  40004,\n",
       "  25180,\n",
       "  15053,\n",
       "  4965,\n",
       "  22499,\n",
       "  5829,\n",
       "  36392,\n",
       "  28579,\n",
       "  15078,\n",
       "  15078,\n",
       "  18602,\n",
       "  12147,\n",
       "  4055,\n",
       "  12366,\n",
       "  37536,\n",
       "  37536,\n",
       "  23191,\n",
       "  16599,\n",
       "  15709,\n",
       "  15709,\n",
       "  9632,\n",
       "  42633,\n",
       "  19662,\n",
       "  23949,\n",
       "  26289,\n",
       "  26289,\n",
       "  24804,\n",
       "  12366,\n",
       "  12366,\n",
       "  38525,\n",
       "  22966,\n",
       "  44858,\n",
       "  44858,\n",
       "  15667,\n",
       "  15053,\n",
       "  8315,\n",
       "  17022,\n",
       "  38400,\n",
       "  2680,\n",
       "  2680,\n",
       "  49390,\n",
       "  49390,\n",
       "  2680,\n",
       "  2680,\n",
       "  43797,\n",
       "  26716,\n",
       "  30935,\n",
       "  32227,\n",
       "  16371,\n",
       "  19662,\n",
       "  19662,\n",
       "  40053,\n",
       "  13170,\n",
       "  45622,\n",
       "  45622,\n",
       "  20822,\n",
       "  36015,\n",
       "  36015,\n",
       "  36015,\n",
       "  9193,\n",
       "  8725,\n",
       "  34767,\n",
       "  34767,\n",
       "  5693,\n",
       "  783,\n",
       "  5664,\n",
       "  8725,\n",
       "  25706,\n",
       "  44657,\n",
       "  44657,\n",
       "  44657,\n",
       "  37356,\n",
       "  21524,\n",
       "  21524,\n",
       "  25706,\n",
       "  6739,\n",
       "  3895,\n",
       "  19662,\n",
       "  15349,\n",
       "  25952,\n",
       "  18761,\n",
       "  27800,\n",
       "  24494,\n",
       "  8673,\n",
       "  2680,\n",
       "  40099,\n",
       "  8725,\n",
       "  3870,\n",
       "  1426,\n",
       "  40489,\n",
       "  45622,\n",
       "  6036,\n",
       "  6036,\n",
       "  6036,\n",
       "  7287,\n",
       "  21866,\n",
       "  31206,\n",
       "  33987,\n",
       "  14258,\n",
       "  8725,\n",
       "  32291,\n",
       "  32291,\n",
       "  8257,\n",
       "  8257,\n",
       "  25952,\n",
       "  41240,\n",
       "  34767,\n",
       "  24742,\n",
       "  22085,\n",
       "  22085,\n",
       "  22085,\n",
       "  22085,\n",
       "  23756,\n",
       "  23756,\n",
       "  48513,\n",
       "  48513,\n",
       "  4803,\n",
       "  1426,\n",
       "  34767,\n",
       "  34767,\n",
       "  25410,\n",
       "  25410,\n",
       "  4005,\n",
       "  19388,\n",
       "  43452,\n",
       "  47610,\n",
       "  47610,\n",
       "  17558,\n",
       "  17558,\n",
       "  17558,\n",
       "  24999,\n",
       "  17601,\n",
       "  15413,\n",
       "  7016,\n",
       "  7016,\n",
       "  12572,\n",
       "  32766,\n",
       "  32766,\n",
       "  22405,\n",
       "  14646,\n",
       "  49534,\n",
       "  3424,\n",
       "  28410,\n",
       "  28410,\n",
       "  38812,\n",
       "  18317,\n",
       "  31125,\n",
       "  35568,\n",
       "  4275,\n",
       "  11494,\n",
       "  10410,\n",
       "  40099,\n",
       "  34769,\n",
       "  42070,\n",
       "  17372,\n",
       "  40779,\n",
       "  40779,\n",
       "  38654,\n",
       "  22798,\n",
       "  10771,\n",
       "  42453,\n",
       "  42453,\n",
       "  26358,\n",
       "  37428,\n",
       "  4508,\n",
       "  10467,\n",
       "  32197,\n",
       "  32197,\n",
       "  34769,\n",
       "  19662,\n",
       "  23949,\n",
       "  48723,\n",
       "  6664,\n",
       "  22289,\n",
       "  12112,\n",
       "  37563,\n",
       "  7587,\n",
       "  7587,\n",
       "  7587,\n",
       "  5223,\n",
       "  25583,\n",
       "  30584,\n",
       "  33857,\n",
       "  34401,\n",
       "  47352,\n",
       "  30225,\n",
       "  8257,\n",
       "  1982,\n",
       "  19573,\n",
       "  33176,\n",
       "  15667,\n",
       "  34689,\n",
       "  12147,\n",
       "  46141,\n",
       "  31209,\n",
       "  22499,\n",
       "  29195,\n",
       "  31209,\n",
       "  31209,\n",
       "  11385,\n",
       "  19709,\n",
       "  45166,\n",
       "  4413,\n",
       "  48649,\n",
       "  24560,\n",
       "  32747,\n",
       "  32694,\n",
       "  32694,\n",
       "  43452,\n",
       "  43452,\n",
       "  40161,\n",
       "  40161,\n",
       "  21919,\n",
       "  19777,\n",
       "  15769,\n",
       "  21919,\n",
       "  43452,\n",
       "  19608,\n",
       "  12112,\n",
       "  12689,\n",
       "  43122,\n",
       "  43122,\n",
       "  21675,\n",
       "  27800,\n",
       "  27800,\n",
       "  27800,\n",
       "  24494,\n",
       "  10891,\n",
       "  24999,\n",
       "  19662,\n",
       "  1688,\n",
       "  1688,\n",
       "  1971,\n",
       "  21889,\n",
       "  27867,\n",
       "  43849,\n",
       "  31663,\n",
       "  11385,\n",
       "  24999,\n",
       "  38400,\n",
       "  10288,\n",
       "  5410,\n",
       "  22379,\n",
       "  31021,\n",
       "  40584,\n",
       "  18092,\n",
       "  9170,\n",
       "  42751,\n",
       "  40179,\n",
       "  40179,\n",
       "  6466,\n",
       "  15156,\n",
       "  43718,\n",
       "  43138,\n",
       "  43138,\n",
       "  27422,\n",
       "  5243,\n",
       "  6756,\n",
       "  25706,\n",
       "  37312,\n",
       "  5006,\n",
       "  33727,\n",
       "  22924,\n",
       "  23612,\n",
       "  23612,\n",
       "  23612,\n",
       "  12404,\n",
       "  19240,\n",
       "  20735,\n",
       "  48723,\n",
       "  38400,\n",
       "  20765,\n",
       "  36191,\n",
       "  46821,\n",
       "  22289,\n",
       "  38400,\n",
       "  48546,\n",
       "  42547,\n",
       "  21316,\n",
       "  17121,\n",
       "  25952,\n",
       "  28579,\n",
       "  19901,\n",
       "  30225,\n",
       "  48649,\n",
       "  36060,\n",
       "  33585,\n",
       "  3005,\n",
       "  24999,\n",
       "  19662,\n",
       "  38425,\n",
       "  46594,\n",
       "  46594,\n",
       "  7794,\n",
       "  1977,\n",
       "  49243,\n",
       "  20524,\n",
       "  20524,\n",
       "  6709,\n",
       "  43452,\n",
       "  34926,\n",
       "  34926,\n",
       "  1426,\n",
       "  34288,\n",
       "  45859,\n",
       "  25952,\n",
       "  25952,\n",
       "  25300,\n",
       "  25952,\n",
       "  18872,\n",
       "  19917,\n",
       "  12325,\n",
       "  15472,\n",
       "  4011,\n",
       "  44806,\n",
       "  38376,\n",
       "  24999,\n",
       "  24999,\n",
       "  48121,\n",
       "  14278,\n",
       "  31209,\n",
       "  6036,\n",
       "  46051,\n",
       "  24999,\n",
       "  25401,\n",
       "  25401,\n",
       "  9632,\n",
       "  9432,\n",
       "  36854,\n",
       "  46505,\n",
       "  38035,\n",
       "  38035,\n",
       "  10288,\n",
       "  5410,\n",
       "  5410,\n",
       "  30584,\n",
       "  20822,\n",
       "  45144,\n",
       "  33107,\n",
       "  33107,\n",
       "  1426,\n",
       "  8725,\n",
       "  5693,\n",
       "  5693,\n",
       "  5409,\n",
       "  6709,\n",
       "  48946,\n",
       "  3424,\n",
       "  42239,\n",
       "  44565,\n",
       "  49738,\n",
       "  49738,\n",
       "  19662,\n",
       "  277,\n",
       "  41240,\n",
       "  35520,\n",
       "  23699,\n",
       "  23699,\n",
       "  27474,\n",
       "  21272,\n",
       "  21272,\n",
       "  10891,\n",
       "  26683,\n",
       "  1594,\n",
       "  1594,\n",
       "  1594,\n",
       "  1594,\n",
       "  23548,\n",
       "  15667,\n",
       "  28563,\n",
       "  19277,\n",
       "  19277,\n",
       "  2223,\n",
       "  29917,\n",
       "  18621,\n",
       "  10492,\n",
       "  34288,\n",
       "  47076,\n",
       "  18621,\n",
       "  18621,\n",
       "  18621,\n",
       "  40161,\n",
       "  13551,\n",
       "  13551,\n",
       "  23418,\n",
       "  29012,\n",
       "  5093,\n",
       "  5093,\n",
       "  5093,\n",
       "  19714,\n",
       "  37979,\n",
       "  13067,\n",
       "  7834,\n",
       "  10333,\n",
       "  24930,\n",
       "  26289,\n",
       "  20959,\n",
       "  8487,\n",
       "  13543,\n",
       "  31082,\n",
       "  31082,\n",
       "  4180,\n",
       "  11220,\n",
       "  1022,\n",
       "  1874,\n",
       "  40099,\n",
       "  49738,\n",
       "  29252,\n",
       "  29252,\n",
       "  25119,\n",
       "  15667,\n",
       "  29152,\n",
       "  3452,\n",
       "  10961,\n",
       "  42545,\n",
       "  24494,\n",
       "  8376,\n",
       "  45616,\n",
       "  13732,\n",
       "  13732,\n",
       "  43548,\n",
       "  43548,\n",
       "  17558,\n",
       "  3722,\n",
       "  3722,\n",
       "  48723,\n",
       "  250,\n",
       "  25400,\n",
       "  25400,\n",
       "  19662,\n",
       "  32435,\n",
       "  15644,\n",
       "  42239,\n",
       "  15667,\n",
       "  44858,\n",
       "  25145,\n",
       "  37312,\n",
       "  15992,\n",
       "  15992,\n",
       "  14646,\n",
       "  48795,\n",
       "  27134,\n",
       "  9038,\n",
       "  38107,\n",
       "  6794,\n",
       "  1384,\n",
       "  8876,\n",
       "  39178,\n",
       "  3197,\n",
       "  29252,\n",
       "  38131,\n",
       "  18007,\n",
       "  18007,\n",
       "  34052,\n",
       "  27920,\n",
       "  9205,\n",
       "  3268,\n",
       "  27920,\n",
       "  30429,\n",
       "  41412,\n",
       "  1426,\n",
       "  37356,\n",
       "  22825,\n",
       "  26537,\n",
       "  181,\n",
       "  181,\n",
       "  45377,\n",
       "  45377,\n",
       "  47352,\n",
       "  31209,\n",
       "  41638,\n",
       "  6128,\n",
       "  5675,\n",
       "  15363,\n",
       "  9245,\n",
       "  9245,\n",
       "  19662,\n",
       "  19662,\n",
       "  11642,\n",
       "  20524,\n",
       "  15199,\n",
       "  15534,\n",
       "  2799,\n",
       "  44186,\n",
       "  44186,\n",
       "  29959,\n",
       "  14357,\n",
       "  40179,\n",
       "  18219,\n",
       "  11399,\n",
       "  5476,\n",
       "  21266,\n",
       "  37536,\n",
       "  26289,\n",
       "  26289,\n",
       "  34329,\n",
       "  22508,\n",
       "  4965,\n",
       "  4965,\n",
       "  33635,\n",
       "  40161,\n",
       "  13551,\n",
       "  18792,\n",
       "  45066,\n",
       "  32734,\n",
       "  44936,\n",
       "  9725,\n",
       "  44608,\n",
       "  44608,\n",
       "  32291,\n",
       "  24706,\n",
       "  37383,\n",
       "  2434,\n",
       "  49534,\n",
       "  24908,\n",
       "  8844,\n",
       "  8844,\n",
       "  8725,\n",
       "  8725,\n",
       "  5693,\n",
       "  24073,\n",
       "  5409,\n",
       "  24999,\n",
       "  9659,\n",
       "  7822,\n",
       "  25087,\n",
       "  25087,\n",
       "  29674,\n",
       "  45357,\n",
       "  9401,\n",
       "  3548,\n",
       "  24021,\n",
       "  24021,\n",
       "  24021,\n",
       "  24999,\n",
       "  11702,\n",
       "  5410,\n",
       "  42857,\n",
       "  4965,\n",
       "  24999,\n",
       "  19662,\n",
       "  32197,\n",
       "  32197,\n",
       "  32197,\n",
       "  39468,\n",
       "  34767,\n",
       "  24073,\n",
       "  23996,\n",
       "  22611,\n",
       "  22611,\n",
       "  20911,\n",
       "  4005,\n",
       "  1426,\n",
       "  12211,\n",
       "  8035,\n",
       "  2112,\n",
       "  2930,\n",
       "  2930,\n",
       "  46346,\n",
       "  9170,\n",
       "  24958,\n",
       "  24255,\n",
       "  18621,\n",
       "  44714,\n",
       "  19662,\n",
       "  15971,\n",
       "  15644,\n",
       "  8898,\n",
       "  6709,\n",
       "  28194,\n",
       "  7016,\n",
       "  22814,\n",
       "  3268,\n",
       "  3268,\n",
       "  29674,\n",
       "  47610,\n",
       "  37621,\n",
       "  47610,\n",
       "  25665,\n",
       "  12885,\n",
       "  7695,\n",
       "  46140,\n",
       "  17796,\n",
       "  17796,\n",
       "  17796,\n",
       "  34329,\n",
       "  35011,\n",
       "  9205,\n",
       "  9205,\n",
       "  3268,\n",
       "  45662,\n",
       "  6497,\n",
       "  23719,\n",
       "  23719,\n",
       "  23719,\n",
       "  13067,\n",
       "  6614,\n",
       "  29440,\n",
       "  ...]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.0933, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 197, 2373,   33,  867, 2142,  429]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6f68f3af38e79a2aaa7d403901face3a23ea1c10b7b7e1341f2157525739495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
